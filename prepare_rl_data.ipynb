{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec66d94-48f1-4859-ae68-8800d945d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from typing import List, Dict\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d3b8c7-67d3-40db-a9d2-8aea3117f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\n",
    "    \"cola_data/in_domain_train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"source\", \"label\", \"first_label\", \"text\"],\n",
    ")\n",
    "test_data = pd.read_csv(\n",
    "    \"cola_data/in_domain_dev.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"source\", \"label\", \"first_label\", \"text\"],\n",
    ")\n",
    "train_data = train_data[[\"text\", \"label\"]]\n",
    "test_data = test_data[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "612afb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Decide whether the following sentence is grammatically acceptable or not. If it is grammatically correct, answer \"acceptable\". If not, answer \"unacceptable\". Only output \"acceptable\" or \"unacceptable\", and do not output any other information.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\n",
    "Your answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6481bf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8551, 4) (527, 4)\n"
     ]
    }
   ],
   "source": [
    "train_data[\"instruction\"] = train_data[\"text\"].apply(\n",
    "    lambda x: prompt.format(sentence=x).strip()\n",
    ")\n",
    "train_data[\"output\"] = train_data[\"label\"].apply(\n",
    "    lambda x: \"unacceptable\" if x == 0 else \"acceptable\"\n",
    ")\n",
    "\n",
    "test_data[\"instruction\"] = test_data[\"text\"].apply(\n",
    "    lambda x: prompt.format(sentence=x).strip()\n",
    ")\n",
    "test_data[\"output\"] = test_data[\"label\"].apply(\n",
    "    lambda x: \"unacceptable\" if x == 0 else \"acceptable\"\n",
    ")\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd1dfb2e-a14e-4d16-b161-4e76788c7078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decide whether the following sentence is grammatically acceptable or not. If it is grammatically correct, answer \"acceptable\". If not, answer \"unacceptable\". Only output \"acceptable\" or \"unacceptable\", and do not output any other information.\n",
      "\n",
      "Sentence: Our friends won't buy this analysis, let alone the next one we propose.\n",
      "\n",
      "Your answer:\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.to_dict(orient=\"records\")\n",
    "test_data = test_data.to_dict(orient=\"records\")\n",
    "\n",
    "print(train_data[0][\"instruction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf755c69-d40d-4090-a009-6753622ad77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"model/Qwen3-0.6B\")\n",
    "\n",
    "\n",
    "def get_rl_data(data_source: str, data: List[Dict[str, str]]):\n",
    "    rl_data = []\n",
    "    for d in tqdm(data):\n",
    "        rl_data.append(\n",
    "            {\n",
    "                \"data_source\": data_source,\n",
    "                \"prompt\": [{\"content\": d[\"instruction\"], \"role\": \"user\"}],\n",
    "                \"reward_model\": {\"ground_truth\": d[\"output\"]},\n",
    "            }\n",
    "        )\n",
    "    return Dataset.from_list(rl_data, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f295c40b-3eba-4fcb-8e8a-cc81da410d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8551/8551 [00:00<00:00, 998426.97it/s]\n",
      "100%|██████████| 527/527 [00:00<00:00, 796539.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['data_source', 'prompt', 'reward_model'],\n",
      "    num_rows: 8551\n",
      "}) Dataset({\n",
      "    features: ['data_source', 'prompt', 'reward_model'],\n",
      "    num_rows: 527\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_train = get_rl_data(\"cola\", train_data)\n",
    "ds_test = get_rl_data(\"cola\", test_data)\n",
    "print(ds_train, ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ead5825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_source': 'cola',\n",
       " 'prompt': [{'content': 'Decide whether the following sentence is grammatically acceptable or not. If it is grammatically correct, answer \"acceptable\". If not, answer \"unacceptable\". Only output \"acceptable\" or \"unacceptable\", and do not output any other information.\\n\\nSentence: Our friends won\\'t buy this analysis, let alone the next one we propose.\\n\\nYour answer:',\n",
       "   'role': 'user'}],\n",
       " 'reward_model': {'ground_truth': 'acceptable'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2209dca7-ee5c-4a34-b0b5-2c3d1e411946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2d7ff7bf514c3eb76a95ffcd2b8c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affab26876424b7ea24cdb41153c601f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "182568"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.to_parquet(\"data/cola_rl/train.parquet\")\n",
    "ds_test.to_parquet(\"data/cola_rl/test.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hqs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
